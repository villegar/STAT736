<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Roberto Villegas-Diaz" />


<title>HW10 - Lab 01: Amplicon Sequence Denoising via DADA2</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Lab 01</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown-header">home</li>
<li>
  <a href="Lab-01-DADA2.html">
    <span class="fa fa-exclamation"></span>

    Tutorial
  </a>
</li>
<li>
  <a href="Lab-01-DADA2.Rmd">
    <span class="fa fa-gear"></span>

    Source
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-newspaper-o"></span>

    Further Reading

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="http://benjjneb.github.io/dada2/">DADA2 Home Page</a>
    </li>
    <li>
      <a href="https://benjjneb.github.io/dada2/bigdata.html">DADA2 Big Data</a>
    </li>
    <li>
      <a href="http://dx.doi.org/10.1038/nmeth.3869">DADA2 Peer-Reviewed Article</a>
    </li>
    <li>
      <a href="http://benjjneb.github.io/dada2/SMBS_DADA2.pdf">DADA2 Slides</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">

      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">HW10 - Lab 01: Amplicon Sequence Denoising via DADA2</h1>
<h4 class="author">Roberto Villegas-Diaz</h4>
<h4 class="date">Sun Dec 8 14:44:07 2019</h4>

</div>


<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<div id="motivation" class="section level2">
<h2><span class="header-section-number">1.1</span> Motivation</h2>
<p>Here we walk through the DADA2 pipeline on a small multi-sample dataset. Our starting point is a set of Illumina-sequenced paired-end fastq files that have been split (“demultiplexed”) by sample and from which the barcodes/adapters/non-natural-bits have already been removed from the sequences.</p>
<p>The end product of the DADA2 algorithm is a sequence table, analogous (but not equivalent in properties) to the ubiquitous “OTU table”, which records the number of times each biological sequence variant was observed in each sample – a “sequence by sample” table.</p>
</div>
<div id="taxonomic-classification" class="section level2">
<h2><span class="header-section-number">1.2</span> Taxonomic Classification</h2>
<p>At the end of this example we also estimate a taxonomic classification of each output sequence – a feature of the data that is often very useful for a microbiologist/ecologist tasked with translating your experimental results into biologically meaningful findings. How and where this taxonomy can be used is addressed later in the workshop. Strictly speaking, as an unsupervised method, the DADA2 algorithm does not do any taxonomic classification; however, it is convenient and useful thing to do right away for specific types of amplicon sequences – especially 16S rRNA amplicons – and so this task has some support in the dada2 package. The statistical problem of 16S sequence fragment classification is actually an interesting and hard one, especially as reference databases rapidly grow and change in quantity and quality. You very well may want to revisit the approach that we use here for your own sequence classification and consider better performing alternatives. The taxonomic classification step is purely independent of DADA2, and any other classification method can be applied to its output of “denoised” amplicon sequences and their abundances.</p>
</div>
<div id="big-data" class="section level2">
<h2><span class="header-section-number">1.3</span> Big Data</h2>
<p>DADA2 actually has very good scaling properties for large datasets of either large reads per sample, large numbers of samples, or both. The dada2 package has recently added some convenience methods for making it easier to do one of the approaches that takes advantage of these computational scaling properties.</p>
<p>Note that there are several reasonable ways to organize your parallelization scheme for running DADA2 on a large dataset. All of these take advantage of the same property, that DADA2 can operate on samples independently because the results – inferred noise-free sequences – are inherently comparable across samples, and even experiments. The most convenient or cost-effective or time-effective approach to parallelization might be different on your avaialable compute resources. I am happy to discuss these alternatives in more detail if you are interested.</p>
<p>The easiest to use parallelization approach is described in <a href="https://benjjneb.github.io/dada2/bigdata.html">the DADA2 Big Data Tutorial</a>, which is an alternative tutorial to this one where the focus is documenting the convenience methods supporting parallelization for DADA2. This particular approach assumes that you have multiple cores available, and enough memory (RAM) to support the simultaneous operation of DADA2 algorithm. Whether this is true depends on both your data and your system.</p>
<p>In my own work, we use a different parallelization approach that makes more sense for the cost structure of Amazon AWS computing. If you plan to use a large academic cluster or large-memory servers for your dada2-ing, then the approach shown in <a href="https://benjjneb.github.io/dada2/bigdata.html">the DADA2 Big Data Tutorial</a> is probably a great choice.</p>
<hr />
</div>
</div>
<div id="getting-ready" class="section level1">
<h1><span class="header-section-number">2</span> Getting ready</h1>
<p>First we load the necessary libraries. If you don’t already have the dada2 package, see the <a href="dada-installation.html">dada2 installation instructions</a>. The ShortRead package is available from <a href="http://bioconductor.org/install/">Bioconductor</a>, and ggplot2 from CRAN or Bioconductor:</p>
<pre class="r"><code>library(dada2); packageVersion(&quot;dada2&quot;)</code></pre>
<pre><code>## [1] &#39;1.12.1&#39;</code></pre>
<pre class="r"><code>library(ShortRead); packageVersion(&quot;ShortRead&quot;)</code></pre>
<pre><code>## [1] &#39;1.42.0&#39;</code></pre>
<pre class="r"><code>library(ggplot2); packageVersion(&quot;ggplot2&quot;)</code></pre>
<pre><code>## [1] &#39;3.2.1&#39;</code></pre>
<p>The data we will be working with are the same as those in the <a href="http://www.mothur.org/wiki/MiSeq_SOP">Mothur Miseq SOP</a> walkthrough. Download the <a href="http://www.mothur.org/w/images/d/d6/MiSeqSOPData.zip">example data used in the Mother MiSeq SOP</a> and unzip it. These files represent longitudinal samples from a mouse post-weaning as well as one mock community control. But for now just consider them as paired-end fastq files to be processed. Download the data, extract it, and then define the following path variable so that it points to the extracted directory on <strong>your</strong> machine:</p>
<pre class="r"><code>path &lt;- &quot;data/MiSeq_SOP/raw_sequences&quot;
dir.exists(path)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>We are going to write our filtered sequences into an adjacent directory, rather than overwrite the raw sequences. Let’s define that path now.</p>
<pre class="r"><code># Make filenames for the filtered fastq files in an adjacent directory.
dirFiltSeqs = file.path(dirname(path), &quot;filtered_sequences&quot;)
dirFiltSeqs</code></pre>
<pre><code>## [1] &quot;data/MiSeq_SOP/filtered_sequences&quot;</code></pre>
<pre class="r"><code>if(!dir.exists(dirFiltSeqs)){
  dir.create(dirFiltSeqs)
}</code></pre>
<p>Now let’s check that the amplicon sequencing files that we expect are present</p>
<pre class="r"><code>fns &lt;- list.files(path, full.names = TRUE)
fns</code></pre>
<pre><code>##  [1] &quot;data/MiSeq_SOP/raw_sequences/F3D0_S188_L001_R1_001.fastq.gz&quot;
##  [2] &quot;data/MiSeq_SOP/raw_sequences/F3D0_S188_L001_R2_001.fastq.gz&quot;
##  [3] &quot;data/MiSeq_SOP/raw_sequences/F3D1_S189_L001_R1_001.fastq.gz&quot;
##  [4] &quot;data/MiSeq_SOP/raw_sequences/F3D1_S189_L001_R2_001.fastq.gz&quot;
##  [5] &quot;data/MiSeq_SOP/raw_sequences/F3D141_S207_L001_R1_001.fastq.gz&quot;
##  [6] &quot;data/MiSeq_SOP/raw_sequences/F3D141_S207_L001_R2_001.fastq.gz&quot;
##  [7] &quot;data/MiSeq_SOP/raw_sequences/F3D142_S208_L001_R1_001.fastq.gz&quot;
##  [8] &quot;data/MiSeq_SOP/raw_sequences/F3D142_S208_L001_R2_001.fastq.gz&quot;
##  [9] &quot;data/MiSeq_SOP/raw_sequences/F3D143_S209_L001_R1_001.fastq.gz&quot;
## [10] &quot;data/MiSeq_SOP/raw_sequences/F3D143_S209_L001_R2_001.fastq.gz&quot;
## [11] &quot;data/MiSeq_SOP/raw_sequences/F3D144_S210_L001_R1_001.fastq.gz&quot;
## [12] &quot;data/MiSeq_SOP/raw_sequences/F3D144_S210_L001_R2_001.fastq.gz&quot;
## [13] &quot;data/MiSeq_SOP/raw_sequences/F3D145_S211_L001_R1_001.fastq.gz&quot;
## [14] &quot;data/MiSeq_SOP/raw_sequences/F3D145_S211_L001_R2_001.fastq.gz&quot;
## [15] &quot;data/MiSeq_SOP/raw_sequences/F3D146_S212_L001_R1_001.fastq.gz&quot;
## [16] &quot;data/MiSeq_SOP/raw_sequences/F3D146_S212_L001_R2_001.fastq.gz&quot;
## [17] &quot;data/MiSeq_SOP/raw_sequences/F3D147_S213_L001_R1_001.fastq.gz&quot;
## [18] &quot;data/MiSeq_SOP/raw_sequences/F3D147_S213_L001_R2_001.fastq.gz&quot;
## [19] &quot;data/MiSeq_SOP/raw_sequences/F3D148_S214_L001_R1_001.fastq.gz&quot;
## [20] &quot;data/MiSeq_SOP/raw_sequences/F3D148_S214_L001_R2_001.fastq.gz&quot;
## [21] &quot;data/MiSeq_SOP/raw_sequences/F3D149_S215_L001_R1_001.fastq.gz&quot;
## [22] &quot;data/MiSeq_SOP/raw_sequences/F3D149_S215_L001_R2_001.fastq.gz&quot;
## [23] &quot;data/MiSeq_SOP/raw_sequences/F3D150_S216_L001_R1_001.fastq.gz&quot;
## [24] &quot;data/MiSeq_SOP/raw_sequences/F3D150_S216_L001_R2_001.fastq.gz&quot;
## [25] &quot;data/MiSeq_SOP/raw_sequences/F3D2_S190_L001_R1_001.fastq.gz&quot;
## [26] &quot;data/MiSeq_SOP/raw_sequences/F3D2_S190_L001_R2_001.fastq.gz&quot;
## [27] &quot;data/MiSeq_SOP/raw_sequences/F3D3_S191_L001_R1_001.fastq.gz&quot;
## [28] &quot;data/MiSeq_SOP/raw_sequences/F3D3_S191_L001_R2_001.fastq.gz&quot;
## [29] &quot;data/MiSeq_SOP/raw_sequences/F3D5_S193_L001_R1_001.fastq.gz&quot;
## [30] &quot;data/MiSeq_SOP/raw_sequences/F3D5_S193_L001_R2_001.fastq.gz&quot;
## [31] &quot;data/MiSeq_SOP/raw_sequences/F3D6_S194_L001_R1_001.fastq.gz&quot;
## [32] &quot;data/MiSeq_SOP/raw_sequences/F3D6_S194_L001_R2_001.fastq.gz&quot;
## [33] &quot;data/MiSeq_SOP/raw_sequences/F3D7_S195_L001_R1_001.fastq.gz&quot;
## [34] &quot;data/MiSeq_SOP/raw_sequences/F3D7_S195_L001_R2_001.fastq.gz&quot;
## [35] &quot;data/MiSeq_SOP/raw_sequences/F3D8_S196_L001_R1_001.fastq.gz&quot;
## [36] &quot;data/MiSeq_SOP/raw_sequences/F3D8_S196_L001_R2_001.fastq.gz&quot;
## [37] &quot;data/MiSeq_SOP/raw_sequences/F3D9_S197_L001_R1_001.fastq.gz&quot;
## [38] &quot;data/MiSeq_SOP/raw_sequences/F3D9_S197_L001_R2_001.fastq.gz&quot;
## [39] &quot;data/MiSeq_SOP/raw_sequences/Icon\r&quot;
## [40] &quot;data/MiSeq_SOP/raw_sequences/Mock_S280_L001_R1_001.fastq.gz&quot;
## [41] &quot;data/MiSeq_SOP/raw_sequences/Mock_S280_L001_R2_001.fastq.gz&quot;</code></pre>
<p>If the packages successfully loaded and your listed files match those here, then you are ready to go through the DADA2 pipeline.</p>
<p> </p>
<hr />
</div>
<div id="filter-trim-sequences" class="section level1">
<h1><span class="header-section-number">3</span> Filter, Trim Sequences</h1>
<div id="prepare-sequence-file-names" class="section level2">
<h2><span class="header-section-number">3.1</span> Prepare sequence file names</h2>
<p>First we read in the file names for all the fastq files and do a little string manipulation to get lists of the forward and reverse fastq files in matched order:</p>
<pre class="r"><code>fastqs &lt;- fns[grepl(&quot;\\.fastq\\.gz$&quot;, fns)]
# Sort ensures forward/reverse files are in same order
fastqs &lt;- sort(fastqs)
# Just the forward read files
fnFs &lt;- fastqs[grepl(&quot;_R1&quot;, fastqs)]
# Just the reverse read files
fnRs &lt;- fastqs[grepl(&quot;_R2&quot;, fastqs)]
# In this case, you can get sample names
# from the first part of the forward read filenames
sample.names &lt;- sapply(strsplit(basename(fnFs), &quot;_&quot;), `[`, 1)
sample.names</code></pre>
<pre><code>##  [1] &quot;F3D0&quot;   &quot;F3D1&quot;   &quot;F3D141&quot; &quot;F3D142&quot; &quot;F3D143&quot; &quot;F3D144&quot; &quot;F3D145&quot; &quot;F3D146&quot;
##  [9] &quot;F3D147&quot; &quot;F3D148&quot; &quot;F3D149&quot; &quot;F3D150&quot; &quot;F3D2&quot;   &quot;F3D3&quot;   &quot;F3D5&quot;   &quot;F3D6&quot;
## [17] &quot;F3D7&quot;   &quot;F3D8&quot;   &quot;F3D9&quot;   &quot;Mock&quot;</code></pre>
</div>
<div id="examine-quality-profiles-of-forward-and-reverse-reads" class="section level2">
<h2><span class="header-section-number">3.2</span> Examine quality profiles of forward and reverse reads</h2>
<p>It is always important to look at your data. We start by visualizing the quality profiles along the sequencing reads.</p>
<p><strong>Visualize the quality profile of the forward reads</strong>:</p>
<pre class="r"><code>plotQualityProfile(fnFs[[1]])</code></pre>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/see-quality-F-1.png" width="672" /></p>
<pre class="r"><code>plotQualityProfile(fnFs[[2]])</code></pre>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/see-quality-F-2.png" width="672" /></p>
<p>The forward reads are of good quality. It is generally a good idea to trim the first 10 bases of Illumina sequences, as error rates are higher and less well-controlled at the start of Illumina sequencing. It is also advisable to trim the very end, for similar reasons. There is no suggestion from the quality profiles that any additional trimming is needed, so for the forward reads we will trim the first 10 nucleotides and truncate at position 240 (trimming the last 10 nucleotides).</p>
<p><strong>Visualize the quality profile of the reverse reads</strong>:</p>
<pre class="r"><code>plotQualityProfile(fnRs[[1]])</code></pre>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/see-quality-R-1.png" width="672" /></p>
<pre class="r"><code>plotQualityProfile(fnRs[[2]])</code></pre>
<pre><code>## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will
## replace the existing scale.</code></pre>
<p><img src="Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/see-quality-R-2.png" width="672" /></p>
<p>The reverse reads have significantly worse quality, especially towards the end of the reads, which is quite common in Illumina paired-end sequencing. This isn’t too worrisome, DADA2 incorporates quality information into its error model so the algorithm is fairly robust to lower quality sequence, but some trimming as the average qualities crash is still a good idea. Here we will trim the first 10 nucleotides (as standard) and truncate at position 160 where the quality distribution crashes.</p>
</div>
<div id="perform-filtering-and-trimming" class="section level2">
<h2><span class="header-section-number">3.3</span> Perform filtering and trimming</h2>
<p>We chose our trimming parameters by inspecting the quality profiles. The filtering parameters we’ll use are standard: maxN=0 (DADA2 requires no Ns), truncQ=2 (quality score 2 in Illumina means “stop using this read”) and maxEE=2. The maxEE parameter sets the maximum number of “expected errors” allowed in a read. Setting a threshold on expected errors is <a href="http://www.drive5.com/usearch/manual/expected_errors.html">a better filter than simply averaging quality scores</a>. We use the fastqPairedFilter function to jointly filter the forward and reverse reads.</p>
<p>Further prepare file names</p>
<pre class="r"><code>if(!dir.exists(dirFiltSeqs)){
  dir.create(dirFiltSeqs)
}
(filtFs &lt;- file.path(dirFiltSeqs, paste0(sample.names, &quot;_F_filt.fastq.gz&quot;)))</code></pre>
<pre><code>##  [1] &quot;data/MiSeq_SOP/filtered_sequences/F3D0_F_filt.fastq.gz&quot;
##  [2] &quot;data/MiSeq_SOP/filtered_sequences/F3D1_F_filt.fastq.gz&quot;
##  [3] &quot;data/MiSeq_SOP/filtered_sequences/F3D141_F_filt.fastq.gz&quot;
##  [4] &quot;data/MiSeq_SOP/filtered_sequences/F3D142_F_filt.fastq.gz&quot;
##  [5] &quot;data/MiSeq_SOP/filtered_sequences/F3D143_F_filt.fastq.gz&quot;
##  [6] &quot;data/MiSeq_SOP/filtered_sequences/F3D144_F_filt.fastq.gz&quot;
##  [7] &quot;data/MiSeq_SOP/filtered_sequences/F3D145_F_filt.fastq.gz&quot;
##  [8] &quot;data/MiSeq_SOP/filtered_sequences/F3D146_F_filt.fastq.gz&quot;
##  [9] &quot;data/MiSeq_SOP/filtered_sequences/F3D147_F_filt.fastq.gz&quot;
## [10] &quot;data/MiSeq_SOP/filtered_sequences/F3D148_F_filt.fastq.gz&quot;
## [11] &quot;data/MiSeq_SOP/filtered_sequences/F3D149_F_filt.fastq.gz&quot;
## [12] &quot;data/MiSeq_SOP/filtered_sequences/F3D150_F_filt.fastq.gz&quot;
## [13] &quot;data/MiSeq_SOP/filtered_sequences/F3D2_F_filt.fastq.gz&quot;
## [14] &quot;data/MiSeq_SOP/filtered_sequences/F3D3_F_filt.fastq.gz&quot;
## [15] &quot;data/MiSeq_SOP/filtered_sequences/F3D5_F_filt.fastq.gz&quot;
## [16] &quot;data/MiSeq_SOP/filtered_sequences/F3D6_F_filt.fastq.gz&quot;
## [17] &quot;data/MiSeq_SOP/filtered_sequences/F3D7_F_filt.fastq.gz&quot;
## [18] &quot;data/MiSeq_SOP/filtered_sequences/F3D8_F_filt.fastq.gz&quot;
## [19] &quot;data/MiSeq_SOP/filtered_sequences/F3D9_F_filt.fastq.gz&quot;
## [20] &quot;data/MiSeq_SOP/filtered_sequences/Mock_F_filt.fastq.gz&quot;</code></pre>
<pre class="r"><code>(filtRs &lt;- file.path(dirFiltSeqs, paste0(sample.names, &quot;_R_filt.fastq.gz&quot;)))</code></pre>
<pre><code>##  [1] &quot;data/MiSeq_SOP/filtered_sequences/F3D0_R_filt.fastq.gz&quot;
##  [2] &quot;data/MiSeq_SOP/filtered_sequences/F3D1_R_filt.fastq.gz&quot;
##  [3] &quot;data/MiSeq_SOP/filtered_sequences/F3D141_R_filt.fastq.gz&quot;
##  [4] &quot;data/MiSeq_SOP/filtered_sequences/F3D142_R_filt.fastq.gz&quot;
##  [5] &quot;data/MiSeq_SOP/filtered_sequences/F3D143_R_filt.fastq.gz&quot;
##  [6] &quot;data/MiSeq_SOP/filtered_sequences/F3D144_R_filt.fastq.gz&quot;
##  [7] &quot;data/MiSeq_SOP/filtered_sequences/F3D145_R_filt.fastq.gz&quot;
##  [8] &quot;data/MiSeq_SOP/filtered_sequences/F3D146_R_filt.fastq.gz&quot;
##  [9] &quot;data/MiSeq_SOP/filtered_sequences/F3D147_R_filt.fastq.gz&quot;
## [10] &quot;data/MiSeq_SOP/filtered_sequences/F3D148_R_filt.fastq.gz&quot;
## [11] &quot;data/MiSeq_SOP/filtered_sequences/F3D149_R_filt.fastq.gz&quot;
## [12] &quot;data/MiSeq_SOP/filtered_sequences/F3D150_R_filt.fastq.gz&quot;
## [13] &quot;data/MiSeq_SOP/filtered_sequences/F3D2_R_filt.fastq.gz&quot;
## [14] &quot;data/MiSeq_SOP/filtered_sequences/F3D3_R_filt.fastq.gz&quot;
## [15] &quot;data/MiSeq_SOP/filtered_sequences/F3D5_R_filt.fastq.gz&quot;
## [16] &quot;data/MiSeq_SOP/filtered_sequences/F3D6_R_filt.fastq.gz&quot;
## [17] &quot;data/MiSeq_SOP/filtered_sequences/F3D7_R_filt.fastq.gz&quot;
## [18] &quot;data/MiSeq_SOP/filtered_sequences/F3D8_R_filt.fastq.gz&quot;
## [19] &quot;data/MiSeq_SOP/filtered_sequences/F3D9_R_filt.fastq.gz&quot;
## [20] &quot;data/MiSeq_SOP/filtered_sequences/Mock_R_filt.fastq.gz&quot;</code></pre>
<p><strong>Execute filtering of forward and reverse reads</strong>:</p>
<pre class="r"><code># Filter
for(i in seq_along(fnFs)) {
  fastqPairedFilter(fn = c(fnFs[i], fnRs[i]),
                    fout = c(filtFs[i], filtRs[i]),
                    trimLeft = c(10, 10),
                    truncLen = c(240, 160),
                    maxN = 0,
                    maxEE = 2,
                    truncQ = 2,
                    compress = TRUE, verbose = TRUE)
}</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D0_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D0_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 7793 paired-sequences, output 7139 (91.6%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D1_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D1_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5869 paired-sequences, output 5314 (90.5%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D141_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D141_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5958 paired-sequences, output 5478 (91.9%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D142_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D142_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 3183 paired-sequences, output 2926 (91.9%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D143_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D143_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 3178 paired-sequences, output 2955 (93%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D144_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D144_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 4827 paired-sequences, output 4323 (89.6%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D145_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D145_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 7377 paired-sequences, output 6762 (91.7%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D146_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D146_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5021 paired-sequences, output 4580 (91.2%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D147_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D147_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 17070 paired-sequences, output 15695 (91.9%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D148_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D148_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 12405 paired-sequences, output 11448 (92.3%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D149_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D149_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 13083 paired-sequences, output 12064 (92.2%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D150_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D150_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5509 paired-sequences, output 5054 (91.7%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D2_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D2_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 19620 paired-sequences, output 18130 (92.4%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D3_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D3_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 6758 paired-sequences, output 6275 (92.9%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D5_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D5_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 4448 paired-sequences, output 4068 (91.5%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D6_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D6_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 7989 paired-sequences, output 7394 (92.6%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D7_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D7_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5129 paired-sequences, output 4772 (93%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D8_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D8_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 5294 paired-sequences, output 4890 (92.4%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D9_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/F3D9_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 7070 paired-sequences, output 6525 (92.3%) filtered paired-sequences.</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/Mock_F_filt.fastq.gz</code></pre>
<pre><code>## Overwriting file:data/MiSeq_SOP/filtered_sequences/Mock_R_filt.fastq.gz</code></pre>
<pre><code>## Read in 4779 paired-sequences, output 4333 (90.7%) filtered paired-sequences.</code></pre>
<p>We now have trimmed and filtered fastq files. The preceding filtering can be replaced by other filtering methods. However, in order for the later DADA2 mergePairs step to work, the filtered forward and reverse reads <strong>must be in matched order</strong>! The fastq files that come off the Illumina machine have this property, and fastqPairedFilter preserves it, but not all filtering tools do so.</p>
<p><strong>Big Data Note:</strong> You may find it more convenient to use the <code>filterAndTrim()</code> wrapper function, as described in <a href="https://benjjneb.github.io/dada2/bigdata.html">the DADA2 Big Data Tutorial</a>.</p>
<p> </p>
</div>
</div>
<div id="dereplicate-sequences" class="section level1">
<h1><span class="header-section-number">4</span> Dereplicate sequences</h1>
<p>In the dereplication step, all reads with identical sequences are combined into “unique sequences” with a corresponding abundance, i.e. the number of reads with that same sequence. Dereplication is a part of most pipelines because it reduces computation time by eliminating redundant comparisons between sequences.</p>
<p>Dereplication in the DADA2 pipeline has one crucial addition: <strong>DADA2 retains a summary of the quality information associated with each unique sequence</strong>. DADA2 constructs a “consensus” quality profile for each unique sequence by averaging the positional qualities from the dereplicated reads. These consensus quality profiles inform the error model of the subsequent denoising step, significantly increasing DADA2’s accuracy.</p>
<p><strong>Dereplicate the filtered fastq files</strong>:</p>
<pre class="r"><code>derepFs &lt;- derepFastq(filtFs, verbose=TRUE)
derepRs &lt;- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) &lt;- sample.names
names(derepRs) &lt;- sample.names</code></pre>
<p>Inspect the derep-class object returned by derepFastq:</p>
<pre class="r"><code>derepFs[[1]]</code></pre>
<pre><code>## derep-class: R object describing dereplicated sequencing reads
## $uniques: 7139 reads in 1866 unique sequences
##   Sequence lengths: min=230, median=230, max=230
## $quals: Quality matrix dimension:  1866 230
##   Consensus quality scores: min=12, median=37.74074, max=39
## $map: Map from reads to unique sequences:  2 2 49 1 62 ...</code></pre>
<p><strong>Data structure notes:</strong> Dereplicated sequences are stored in the <code>$uniques</code> integer vector, which is named by the unique sequence and valued by the abundance of that sequence. Consensus quality scores are stored in the <code>$quals</code> matrix: rows correspond to unique sequences and columns to nucleotide position. The <code>$map</code> vector maps the reads into the <code>$uniques</code> vector, and is used later when we merge the forward and reverse reads.</p>
<p> </p>
</div>
<div id="denoise-sequences" class="section level1">
<h1><span class="header-section-number">5</span> Denoise Sequences</h1>
<p>We are now ready to apply DADA2’s core sequence denoising algorithm to the dereplicated sequences. This is the step where we infer the “real” amplicon sequences, as opposed to sequences that contain one or more errors.</p>
<p>First a key consideration: DADA2 depends on a parametric error model, and we do not know the error rates for this dataset. Fortunately, DADA2 can jointly infer the error-rate parameters and the composition of the sample, at the cost of additional computation time. This is done by implementing an EM-like algorithm in which the error rates and the set of true sequences are alternately estimated until convergence.</p>
<p>To perform this joint inference with <code>dada(...)</code> we pass it the <code>selfConsist=TRUE</code> flag (if <code>selfConsist=FALSE</code> it simply uses the provided error rates). As in many optimization problems, the algorithm must begin with an initial guess. For this we take a set of error rates estimated from another Miseq 2x250 sequencing run (called <code>tperr1</code>, included with the package) and inflate them, as it is better to start with error rates that are too high than too low.</p>
<p><strong>Perform joint sample inference and error rate estimation</strong> (takes a few minutes):</p>
<pre class="r"><code>dadaFs &lt;- dada(derepFs, err=inflateErr(tperr1,3),
               selfConsist = TRUE)</code></pre>
<pre><code>## selfConsist step 1 ....................
##    selfConsist step 2
##    selfConsist step 3
##    selfConsist step 4
##    selfConsist step 5
## Convergence after  5  rounds.</code></pre>
<pre class="r"><code>dadaRs &lt;- dada(derepRs, err=inflateErr(tperr1,3),
               selfConsist = TRUE)</code></pre>
<pre><code>## selfConsist step 1 ....................
##    selfConsist step 2
##    selfConsist step 3
##    selfConsist step 4
##    selfConsist step 5
##    selfConsist step 6
## Convergence after  6  rounds.</code></pre>
<p>Inspecting the dada-class object returned by dada:</p>
<pre class="r"><code>dadaFs[[1]]</code></pre>
<pre><code>## dada-class: object describing DADA2 denoising results
## 134 sequence variants were inferred from 1866 input unique sequences.
## Key parameters: OMEGA_A = 1e-40, OMEGA_C = 1e-40, BAND_SIZE = 16</code></pre>
<p>The dada algorithm inferred 134 real variants from the 1866 unique sequences in the first sample. There is much more to the dada-class return object than this (see help(“dada-class”) for some info), including multiple diagnostics about the quality of each inferred sample sequence, but that is beyond the scope of an introductory tutorial. Let’s do one check on the quality of the error-rate estimation though before continuing.</p>
<p><strong>Visualize estimated error rates</strong>:</p>
<pre class="r"><code>plotErrors(dadaFs[[1]], nominalQ=TRUE)</code></pre>
<pre><code>## Warning: Transformation introduced infinite values in continuous y-axis

## Warning: Transformation introduced infinite values in continuous y-axis</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/plot-errors-1.png" width="672" /></p>
<p>The error rates for each possible transition (eg. A-&gt;C, A-&gt;G, …) are shown. The points are the observed error rates for each consensus quality score. The black line is the estimated error rates after convergence. The red line is the error rates expected under the nominal definition of the Q-value.</p>
<p>The black line (the estimated rates) seem to be fitting the observed rates well, and the error rates drop with increased quality as expected. Everything looks reasonable and we proceed with confidence.</p>
<p> </p>
</div>
<div id="merge-paired-reads" class="section level1">
<h1><span class="header-section-number">6</span> Merge paired reads</h1>
<p>The forward and reverse reads in this dataset are highly overlapping, which allows us to further reduce the error rate by merging those overlapping reads together. Note that in the DADA2 pipeline merging is perfomed <strong>after</strong> denoising the forward read and the reverse reads. The core function here is mergePairs, which depends on the forward and reverse reads being in matching order at the time they were dereplicated!</p>
<p><strong>Merge the denoised forward and reverse reads</strong>:</p>
<pre class="r"><code>mergers &lt;- mergePairs(dadaFs, derepFs,
                      dadaRs, derepRs,
                      verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])</code></pre>
<pre><code>##                                                                                                                                                                                                                                    sequence
## 1  GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGAAGATCAAGTCAGCGGTAAAATTGAGAGGCTCAACCTCTTCGAGCCGTTGAAACTGGTTTTCTTGAGTGAGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCTCAACTGACGCTCATGCACGAAAGTGTGGGT
## 2  GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGG
## 3  GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTGTTAAGTCAGCGGTCAAATGTCGGGGCTCAACCCCGGCCTGCCGTTGAAACTGGCGGCCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCATACCGGCGCCCGACTGACGCTGAGGCACGAAAGCGTGGGT
## 4  GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGGCTTTTAAGTCAGCGGTAAAAATTCGGGGCTCAACCCCGTCCGGCCGTTGAAACTGGGGGCCTTGAGTGGGCGAGAAGAAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCCTTCCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGG
## 5  GCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGCAGGCGGACTCTCAAGTCAGCGGTCAAATCGCGGGGCTCAACCCCGTTCCGCCGTTGAAACTGGGAGCCTTGAGTGCGCGAGAAGTAGGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACTCCGATTGCGAAGGCAGCCTACCGGCGCGCAACTGACGCTCATGCACGAAAGCGTGGGT
## 6 GCAAGCGTTATCCGGAATTACTGGGTGTAAAGGGAGCGTAGACGGTAATGCAAGTCTGGAGTGAAAGGCGGGGGCCCAACCCCCGGACTGCTCTGGAAACTGTGTAACTGGAGTGCAGGAGAGGCAGGCGGAATTCCTAGTGTAGCGGTGAAATGCGTAGATATTAGGAGGAACACCAGTGGCGAAGGCGGCCTGCTGGACTGTAACTGACGTTGAGGCTCGAAAGCGTGGGG
##   abundance forward reverse nmatch nmismatch nindel prefer accept
## 1       582       1       1    148         0      0      1   TRUE
## 2       495       2       2    148         0      0      1   TRUE
## 3       450       3       4    148         0      0      1   TRUE
## 4       442       4       3    148         0      0      2   TRUE
## 5       341       5       6    148         0      0      1   TRUE
## 6       282      10       7    147         0      0      2   TRUE</code></pre>
<p>We now have a data.frame for each sample with the merged <code>$sequence</code>, its <code>$abundance</code>, and the indices of the merged <code>$forward</code> and <code>$reverse</code> denoised sequences. Paired reads that did not exactly overlap were removed by <code>mergePairs()</code>.</p>
<p> </p>
</div>
<div id="construct-sequence-table" class="section level1">
<h1><span class="header-section-number">7</span> Construct sequence table</h1>
<p>We can now construct a “sequence table” analogous to the “OTU table” produced by OTU methods.</p>
<p>We also drop the Mock community portion of the data at this point.</p>
<p><strong>Construct sequence table</strong>:</p>
<pre class="r"><code>seqtab &lt;- makeSequenceTable(mergers[names(mergers) != &quot;Mock&quot;])
dim(seqtab)</code></pre>
<pre><code>## [1]  19 276</code></pre>
<pre class="r"><code># Inspect distribution of sequence lengths
table(nchar(colnames(seqtab)))</code></pre>
<pre><code>##
## 231 232 233 234 235
##   1  86 183   5   1</code></pre>
<p>The sequence table is a matrix with rows corresponding (and named by) the samples and columns corresponding to (and named by) the sequence variants. It is worth checking on the distribution of sequence lengths after merging. Here we see a narrow range of sequence lengths, as we expect. If some sequences are much longer or shorter than expected, it may be worth removing those sequences as they may be the result of non-specific priming.</p>
<p> </p>
</div>
<div id="remove-chimeras" class="section level1">
<h1><span class="header-section-number">8</span> Remove chimeras</h1>
<p>The dada() algorithm removes substitution and indel errors, but it does not remove chimeras. That is, chimeras that were present in the sequenced sample are included in the sequence table we generated. Therefore, we now remove the chimeric sequences.</p>
<p>The accuracy of the sequences after the dada-denoising step makes identifying chimeras easier than it is when dealing with fuzzy OTUs. The DADA2 method to do this is by identifying all sequences which can be exactly reconstructred as a bimera (two-parent chimera) from more abundant sequences. See the help file ?isBimeraDenovo for more information.</p>
<p><strong>Remove chimeric sequences</strong>:</p>
<pre class="r"><code>seqtab.nochim &lt;- removeBimeraDenovo(seqtab, verbose=TRUE)
dim(seqtab.nochim)</code></pre>
<pre><code>## [1]  19 223</code></pre>
<pre class="r"><code>sum(seqtab.nochim)/sum(seqtab)</code></pre>
<pre><code>## [1] 0.964846</code></pre>
<p>The fraction of chimeras varies based on factors including experimental procedures and sample complexity, but can be substantial. Here chimeras make up about 20% of the inferred sequence variants, but those variants account for &lt;4% of the total sequence reads.</p>
<p>This is the final product of the core DADA2 pipeline: a sequence table that contains the counts of each denoised sequence variant in each sample.</p>
<p> </p>
</div>
<div id="assign-taxonomy" class="section level1">
<h1><span class="header-section-number">9</span> Assign taxonomy</h1>
<p>It is common at this point, especially in 16S or 18S amplicon sequencing, to classify denoised sequence variants taxonomically. The DADA2 package provides a native implementation of <a href="http://www.ncbi.nlm.nih.gov/pubmed/17586664">the RDP’s naive Bayesian classifier</a> for this purpose. The assignTaxonomy(…) function takes a set of sequences and a training set of taxonomically classified sequences, and outputs the taxonomic assignments with at least minBoot bootstrap confidence.</p>
<p>Appropriately formatted training fasta files for</p>
<ul>
<li>the RDP training set 16,</li>
<li>the RDP training set 14,</li>
<li>the GreenGenes 13.8 release clustered at 97% identity, and</li>
<li>the Silva reference database</li>
</ul>
<p>are <a href="https://www.dropbox.com/sh/mfcivbudmc21cqt/AAB1l-AUM5uKvjrR33ct-cTXa?dl=0">available for download here</a>.</p>
<p>Download <a href="rdp_train_set_16.fa.gz">the rdp_train_set_16.fa.gz file</a>, and place it in the directory with the fastq files (if you don’t already have it).</p>
<p><strong>Assign taxonomy:</strong></p>
<pre class="r"><code>taxMat &lt;- assignTaxonomy(seqs = seqtab.nochim,
                         refFasta = &quot;data/rdp_train_set_16.fa.gz&quot;)
colnames(taxMat) &lt;- c(&quot;Kingdom&quot;, &quot;Phylum&quot;, &quot;Class&quot;, &quot;Order&quot;, &quot;Family&quot;, &quot;Genus&quot;)
table(taxMat[, &quot;Phylum&quot;])</code></pre>
<pre><code>##
##              Actinobacteria               Bacteroidetes
##                           6                          17
## Candidatus_Saccharibacteria   Cyanobacteria/Chloroplast
##                           1                           3
##         Deinococcus-Thermus                  Firmicutes
##                           1                         185
##              Proteobacteria                 Tenericutes
##                           4                           1
##             Verrucomicrobia
##                           1</code></pre>
<p>Unsurprisingly, Bacteroidetes and Firmicutes are among these fecal samples.</p>
<p> </p>
</div>
<div id="evaluate-accuracy" class="section level1">
<h1><span class="header-section-number">10</span> Evaluate accuracy</h1>
<p>One of the provided samples was of a “mock community”, in which 20 known strains were mixed together and amplicon-sequenced (the mock community is supposed to be 21 strains, but P. acnes was absent in this instance). The reference sequences corresponding to these strains were provided along with the fastq files in the downloaded zip archive. We dropped the Mock sample when making our sequence table, but we can go back to that sample and compare the sequence variants inferred by DADA2 to the expected composition of the community.</p>
<p><strong>DADA2 accuracy on mock community</strong>:</p>
<pre class="r"><code>unqs.mock &lt;- getUniques(removeBimeraDenovo(mergers[[&quot;Mock&quot;]], verbose=TRUE))</code></pre>
<pre><code>## Identified 0 bimeras out of 20 input sequences.</code></pre>
<pre class="r"><code>message(&quot;\n&quot;, &quot;DADA2 inferred &quot;, length(unqs.mock), &quot; unique sequences present in the Mock community.\n&quot;)</code></pre>
<pre><code>##
## DADA2 inferred 20 unique sequences present in the Mock community.</code></pre>
<pre class="r"><code>mockRef &lt;- readFasta(&quot;data/MiSeq_SOP/HMP_MOCK.v35.fasta.gz&quot;)
match.ref &lt;- sum(sapply(names(unqs.mock), function(x) any(grepl(x, as.character(sread(mockRef))))))
message(&quot;Of those, &quot;, sum(match.ref), &quot; were exact matches to the expected reference sequences.\n&quot;)</code></pre>
<pre><code>## Of those, 20 were exact matches to the expected reference sequences.</code></pre>
<p>This mock community dataset contained <strong>20</strong> bacterial strains. DADA2 found <strong>20</strong> unique sequences all of which <strong>exactly</strong> match the reference genomes of the expected community members. The residual error rate after the DADA2 pipeline is <strong>0%</strong>.</p>
<p>In comparison, when the Mothur pipeline is run on this same dataset, <a href="http://www.mothur.org/wiki/MiSeq_SOP#Assessing_error_rates">it finds 35 OTUs in this Mock community sample</a>. Not only is DADA2 inferring exact sequences instead of fuzzy 97% OTUs, it is making fewer false positive inferences than the OTU construction methods. This is a meaningful difference, even for a dataset this small and simple.</p>
<p><strong>Here ends the DADA2 portion of the tutorial</strong>.</p>
<hr />
</div>
<div id="handoff-to-phyloseq" class="section level1">
<h1><span class="header-section-number">11</span> Handoff to phyloseq</h1>
<p>The DADA2 pipeline produced a sequence table and a taxonomy table which is appropriate for further analysis in phyloseq. We’ll also include the small amount of metadata we have – the samples are named by the gender (G), mouse subject number (X) and the day post-weaning (Y) it was sampled (eg. GXDY).</p>
<p><strong>Import into phyloseq</strong>:</p>
<pre class="r"><code>library(phyloseq); packageVersion(&quot;phyloseq&quot;)</code></pre>
<pre><code>## [1] &#39;1.28.0&#39;</code></pre>
<pre class="r"><code>library(ggplot2); packageVersion(&quot;ggplot2&quot;)</code></pre>
<pre><code>## [1] &#39;3.2.1&#39;</code></pre>
<pre class="r"><code>theme_set(theme_bw())
# Make a data.frame holding the sample data
samples.out &lt;- rownames(seqtab.nochim)
subject &lt;- sapply(strsplit(samples.out, &quot;D&quot;), `[`, 1)
gender &lt;- substr(subject,1,1)
subject &lt;- substr(subject,2,999)
day &lt;- as.integer(sapply(strsplit(samples.out, &quot;D&quot;), `[`, 2))
samdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When &lt;- &quot;Early&quot;
samdf$When[samdf$Day&gt;100] &lt;- &quot;Late&quot;
rownames(samdf) &lt;- samples.out

# Construct phyloseq object (straightforward from dada2 outputs)
ps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),
               sample_data(samdf),
               tax_table(taxMat))
ps</code></pre>
<pre><code>## phyloseq-class experiment-level object
## otu_table()   OTU Table:         [ 223 taxa and 19 samples ]
## sample_data() Sample Data:       [ 19 samples by 4 sample variables ]
## tax_table()   Taxonomy Table:    [ 223 taxa by 6 taxonomic ranks ]</code></pre>
<p>We are now ready to use phyloseq.</p>
<p><strong>Visualize alpha-diversity</strong>: Use <code>plot_richness</code></p>
<pre class="r"><code>plot_richness(ps,
              x=&quot;Day&quot;,
              measures=c(&quot;Shannon&quot;, &quot;Simpson&quot;),
              color=&quot;When&quot;)</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/richness-1.png" width="672" /></p>
<p>No obvious systematic difference in alpha-diversity between early and late samples.</p>
<p><strong>Ordinate</strong>:</p>
<pre class="r"><code>ord.nmds.bray &lt;- ordinate(ps,
                          method=&quot;NMDS&quot;,
                          distance=&quot;bray&quot;)</code></pre>
<pre><code>## Square root transformation
## Wisconsin double standardization
## Run 0 stress 0.09114477
## Run 1 stress 0.09041719
## ... New best solution
## ... Procrustes: rmse 0.02815118  max resid 0.07072116
## Run 2 stress 0.1592918
## Run 3 stress 0.09041729
## ... Procrustes: rmse 6.289091e-05  max resid 0.0001102424
## ... Similar to previous best
## Run 4 stress 0.09008214
## ... New best solution
## ... Procrustes: rmse 0.01286277  max resid 0.04036441
## Run 5 stress 0.1603284
## Run 6 stress 0.1591518
## Run 7 stress 0.09114477
## Run 8 stress 0.09184283
## Run 9 stress 0.09114484
## Run 10 stress 0.1597714
## Run 11 stress 0.09184284
## Run 12 stress 0.1432116
## Run 13 stress 0.09008213
## ... New best solution
## ... Procrustes: rmse 2.898092e-05  max resid 8.903143e-05
## ... Similar to previous best
## Run 14 stress 0.09184284
## Run 15 stress 0.09114479
## Run 16 stress 0.09184283
## Run 17 stress 0.09184299
## Run 18 stress 0.09184283
## Run 19 stress 0.09114477
## Run 20 stress 0.09008213
## ... New best solution
## ... Procrustes: rmse 6.250204e-06  max resid 1.094682e-05
## ... Similar to previous best
## *** Solution reached</code></pre>
<pre class="r"><code>plot_ordination(physeq = ps,
                ordination = ord.nmds.bray,
                color=&quot;When&quot;,
                title=&quot;Bray NMDS&quot;) +
  geom_point(size = 6)</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/ordinate-1.png" width="672" /></p>
<p>Ordination picks out a clear separation between the early and late samples.</p>
<p><strong>Bar plot</strong>:</p>
<pre class="r"><code>top20 &lt;- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 &lt;- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 &lt;- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x=&quot;Day&quot;, fill=&quot;Family&quot;) + facet_wrap(~When, scales=&quot;free_x&quot;)</code></pre>
<p><img src="https://raw.githubusercontent.com/villegar/STAT736/master/HW10/Lab-01\%20DADA2/Lab-01-DADA2.Roberto.Villegas-Diaz_files/figure-html/bar-plot-1.png" width="672" /></p>
<p>Nothing glaringly obvious jumps out from the taxonomic distribution of the top 20 sequences to explain the early-late differentiation.</p>
<p>This was just a bare bones demonstration of how the data from DADA2 can be easily imported into phyloseq and interrogated. For further examples on the many analyses possible with phyloseq, see <a href="https://joey711.github.io/phyloseq/">the phyloseq web site</a>.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
